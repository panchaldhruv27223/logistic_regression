{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5c6ebc",
   "metadata": {},
   "source": [
    " ## Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3ecbc",
   "metadata": {},
   "source": [
    "Linear Regression: \n",
    "- Linear regression is used when the dependent variable (the variable you want to predict) is continuous. It predicts a numeric value, making it suitable for regression problems. For example, predicting house prices, stock prices, or temperature.\n",
    "- Linear regression uses a linear equation to model the relationship between the independent variables and the continuous dependent variable. The equation is of the form Y = a + bX, where Y is the predicted value, X is the independent variable, and a and b are coefficients.\n",
    "- Linear regression is suitable for problems where you want to predict a numeric value, such as predicting sales revenue, estimating a person's age, or forecasting future stock prices.\n",
    "\n",
    "Logistic Regression: \n",
    "- Logistic regression is used when the dependent variable is binary or categorical, typically representing two classes (0 or 1, Yes or No, True or False). It predicts the probability that an instance belongs to a particular class, making it suitable for classification problems. For example, predicting whether an email is spam or not, whether a customer will buy a product (yes/no), or whether a patient has a disease (yes/no).\n",
    "- Logistic regression uses the logistic function (also known as the sigmoid function) to model the relationship between the independent variables and the binary dependent variable. The logistic function maps any real-valued number into a value between 0 and 1, representing the probability of belonging to one of the two classes.\n",
    "- Logistic regression is more appropriate when you want to solve classification problems, where the outcome is binary or categorical. For instance, consider a scenario where you want to predict whether a student will pass or fail an exam based on features like study time, previous exam scores, and attendance. In this case, logistic regression can provide the probability of passing (class 1) or failing (class 0) for each student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6826ab",
   "metadata": {},
   "source": [
    "## Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a66d92",
   "metadata": {},
   "source": [
    "The cost function used in logistic regression is often referred to as the \"logistic loss\" or \"cross-entropy loss\" function. It measures the error between the predicted probabilities of the logistic regression model and the actual binary outcomes in the dataset. The goal during training is to minimize this cost function. Here's the formula for the logistic loss function:\n",
    "\n",
    "For a single training example with true label y and predicted p:\n",
    "Cost(y,p)= -y*log(p) - (1-y)log(1-p)\n",
    "\n",
    "If y=1, the cost becomes −log(p), which punishes the model more for predicting a low probability when the true label is 1.\n",
    "\n",
    "If y=0, the cost becomes −log(1−p), which punishes the model more for predicting a high probability when the true label is 0.\n",
    "\n",
    "To optimize the logistic regression model, you typically use an optimization algorithm to find the model parameters (coefficients) that minimize the overall cost across the entire training dataset. The most commonly used optimization algorithm for logistic regression is gradient descent. \n",
    "\n",
    "Adjust the model parameters in the opposite direction of the gradient to minimize the cost. This is done iteratively using a learning rate, which determines the step size for parameter updates.\n",
    "\n",
    "repeat until convergance :{\n",
    "\n",
    "    wj = wj - Alpha*(d/dw(J(w,b))\n",
    "\n",
    "}\n",
    "\n",
    "by which we can are optimizing the values of coefficent of feature w1,w2,w3,w4,...,wj.\n",
    "we are not optimize the value of B, which is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef542840",
   "metadata": {},
   "source": [
    "## Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82833bf",
   "metadata": {},
   "source": [
    "Regularization is a technique used in logistic regression to prevent overfitting, which occurs when a model learns to fit the training data too closely, capturing noise and making it perform poorly on unseen data. Regularization introduces a penalty term into the logistic regression cost function, discouraging the model from assigning excessively large weights to features. It encourages the model to have smaller and more balanced feature coefficients, which can improve generalization to new, unseen data.\n",
    "\n",
    "There are two common types of regularization used in logistic regression:\n",
    "\n",
    "L1 Regularization (Lasso Regularization):\n",
    "\n",
    "In L1 regularization, the cost function is augmented by adding the absolute values of the feature coefficients (weights) as a penalty term.\n",
    "\n",
    "new cost function :\n",
    "\n",
    "Cost(y,p)=−ylog(p) - (1−y)log(1−p) + λ sum(WI)\n",
    "Here, WI, represents the weights of individual features, and λ controls the strength of regularization (the regularization parameter).\n",
    "L1 regularization tends to produce sparse models because it encourages many feature coefficients to become exactly zero. This is beneficial for feature selection, as it effectively removes less relevant features from the model.\n",
    "\n",
    "\n",
    "L2 Regularization (Ridge Regularization):\n",
    "\n",
    "In L2 regularization, the cost function is augmented by adding the squared values of the feature coefficients as a penalty term.\n",
    "\n",
    "new cost function :\n",
    "\n",
    "Cost(y,p)=−ylog(p) - (1−y)log(1−p) + λ*sum_of_square_of(WI)\n",
    "\n",
    "Similar to L1 regularization,\n",
    "λ controls the strength of regularization.\n",
    "L2 regularization encourages all feature coefficients to be small but does not force them to become exactly zero. It tends to produce models with small, non-zero weights for all features.\n",
    "\n",
    "Elastic net regularization,\n",
    "\n",
    "Cost(y,p)=−ylog(p) - (1−y)log(1−p) + λ1 sum(WI) + λ2*sum_of_square_of(WI)\n",
    "\n",
    "in Elastic net regularization it add both l1 and l2 penalty term, elastic net is used for both feature selection and preventing over fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bef258",
   "metadata": {},
   "source": [
    "## Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b39f3",
   "metadata": {},
   "source": [
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "\n",
    "True Positive Rate\n",
    "False Positive Rate\n",
    "\n",
    "True Positive Rate (TPR) is a synonym for recall and is therefore defined as follows:\n",
    "\n",
    "TPR = TP/TP+FN\n",
    "\n",
    "\n",
    "False Positive Rate (FPR) is defined as follows:\n",
    "\n",
    "FPR = FP/FP+TN\n",
    "\n",
    "AUC stands for Area Under the Curve, and the AUC curve represents the area under the ROC curve. It measures the overall performance of the binary classification model. As both TPR and FPR range between 0 to 1, So, the area will always lie between 0 and 1, and A greater value of AUC denotes better model performance. Our main goal is to maximize this area in order to have the highest TPR and lowest FPR at the given threshold. The AUC measures the probability that the model will assign a randomly chosen positive instance a higher predicted probability compared to a randomly chosen negative instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da8f3a",
   "metadata": {},
   "source": [
    "## Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532f668",
   "metadata": {},
   "source": [
    "Feature selection is an important step in building a logistic regression model. It involves choosing a subset of relevant features from the available set of predictors to improve model performance and reduce the risk of overfitting. \n",
    "\n",
    "Feature selection techniques:\n",
    "- We can select feature manually\n",
    "- L1 regularization\n",
    "- Variance threshold\n",
    "- Feature Importance from Tree-Based Models\n",
    "\n",
    "Using feature selection techniques we can improve our model performance, model take less time for computation, it take less space, Reduced Overfitting, Potentially Better Generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef1026",
   "metadata": {},
   "source": [
    "## Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b0057",
   "metadata": {},
   "source": [
    "Handling imbalanced datasets in logistic regression is essential because logistic regression models tend to be biased towards the majority class when there is a significant class imbalance. The majority class typically has more data, which can lead to the model having a higher accuracy for the majority class but poor performance on the minority class.\n",
    "- Resampling Techniques : Undersampling, Oversampling.\n",
    "- Smote(Resampling techniques)\n",
    "- interpolation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab3863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "367cf12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 3, 3, 2, 1, 2, 5, 1, 2, 8]),\n",
       " array([ 3,  1,  7,  7,  2,  3, 10,  7,  5,  8]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed()\n",
    "X1 = np.random.randint(1,11,10)\n",
    "X2 = np.random.randint(1,11,10)\n",
    "X1,X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "049fb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1,1,1,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18bd8bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  y\n",
       "0   6   3  1\n",
       "1   3   1  1\n",
       "2   3   7  1\n",
       "3   2   7  0\n",
       "4   1   2  0\n",
       "5   2   3  0\n",
       "6   5  10  0\n",
       "7   1   7  0\n",
       "8   2   5  0\n",
       "9   8   8  0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"X1\":X1,\"X2\":X2,\"y\":y})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b432dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"y\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51ca6ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    7\n",
       "1    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"y\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fa5735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(k_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86ea8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"X1\",\"X2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0854ff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2\n",
       "0   6   3\n",
       "1   3   1\n",
       "2   3   7\n",
       "3   2   7\n",
       "4   1   2\n",
       "5   2   3\n",
       "6   5  10\n",
       "7   1   7\n",
       "8   2   5\n",
       "9   8   8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be196a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"y\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2efe2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10fb5546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bcd7312e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec9dd7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1  X2\n",
       "0    6   3\n",
       "1    3   1\n",
       "2    3   7\n",
       "3    2   7\n",
       "4    1   2\n",
       "5    2   3\n",
       "6    5  10\n",
       "7    1   7\n",
       "8    2   5\n",
       "9    8   8\n",
       "10   4   1\n",
       "11   3   2\n",
       "12   5   2\n",
       "13   3   6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60003365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75859eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9f28181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7\n",
       "0    7\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29110f20",
   "metadata": {},
   "source": [
    "## Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example, what can be done if there is multicollinearity among the independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f3b33",
   "metadata": {},
   "source": [
    "Some common issues are :\n",
    "\n",
    "1. Multicollinearity: Multicollinearity occurs when two or more independent variables in the model are highly correlated      with each other. This can make it challenging to interpret the individual contributions of these variables to the target    variable.\n",
    "   Solve by using covariance, vif, dimensionality reduction...(EX if there are two feature which is highly corelated then      we can simply take any one from that two)\n",
    "   \n",
    "   \n",
    "2. Imbalanced Datasets: Class imbalance, where one class significantly outnumbers the other, can lead to biased model          predictions, as logistic regression may favor the majority class.\n",
    "   Solve by using resampling, interpolation...(if we have two output category 0 and 1 and the number of 0 is 100 and the      number of 1 is 900 so we have to make more sample of 0 category or we can choose subset of 1 ccategory and make number      of zero and 1 are same)\n",
    "   \n",
    "   \n",
    "3. Outliers: Outliers in the data can distort the logistic regression model's coefficients and predictions.\n",
    "   Solution are visualization, statistical tests, or outlier detection algorithms.(we can drop outliers or if they are        important then we can handle them by some techniques like anomaly detection.)\n",
    "  \n",
    "  \n",
    "4. Missing Data: Missing data can impact model training and prediction.\n",
    "   Solve by fill the value by mean, mode, median, predict value by using some ml model.\n",
    "\n",
    "\n",
    "5. Model Evaluation: Selecting the appropriate evaluation metric is crucial for logistic regression models.\n",
    "   Solution, Choose evaluation metrics based on the problem and class distribution, such as accuracy, precision, recall,      F1-score, AUC-ROC, or AUC-PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
